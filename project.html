<!DOCTYPE html>
<html lang="en">
  <head>
    <title>Diwakar V. Singh</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    
    <link href="https://fonts.googleapis.com/css?family=Poppins:300,400,500,600,700" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Montserrat:300,400,500,700" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Herr+Von+Muellerhoff" rel="stylesheet">

    <link rel="stylesheet" href="css/open-iconic-bootstrap.min.css">
    <link rel="stylesheet" href="css/animate.css">
    
    <link rel="stylesheet" href="css/owl.carousel.min.css">
    <link rel="stylesheet" href="css/owl.theme.default.min.css">
    <link rel="stylesheet" href="css/magnific-popup.css">

    <link rel="stylesheet" href="css/aos.css">

    <link rel="stylesheet" href="css/ionicons.min.css">

    <link rel="stylesheet" href="css/bootstrap-datepicker.css">
    <link rel="stylesheet" href="css/jquery.timepicker.css">

    
    <link rel="stylesheet" href="css/flaticon.css">
    <link rel="stylesheet" href="css/icomoon.css">
    <link rel="stylesheet" href="css/style.css">
  </head>
  <body>

	<div id="colorlib-page">
		<a href="#" class="js-colorlib-nav-toggle colorlib-nav-toggle"><i></i></a>
		<aside id="colorlib-aside" role="complementary" class="js-fullheight text-center">
			<h1 id="colorlib-logo"><a href="index.html"><span class="img" style="background-image: url(images/author.jpg);"></span>Diwakar</a></h1>
			<nav id="colorlib-main-menu" role="navigation">
				<ul>
					<li><a href="index.html">Home</a></li>
					<li><a href="about.html">About Me</a></li>
					<li><a href="collection.html">Courses & Experience</a></li>
					<li class="colorlib-active"><a href="project.html">Projects & Publications</a></li>
					<li><a href="contact.html">Contact</a></li>
				</ul>
			</nav>
		</aside> <!-- END COLORLIB-ASIDE -->



		<div id="colorlib-main">
			
			<section class="ftco-section ftco-bread">
				<div class="container">
				<div class="row no-gutters slider-text justify-content-center align-items-center">
	          	<div class="col-md-8 ftco-animate">
	          	<p class="breadcrumbs"><span class="mr-2"><a href="index.html">Home</a></span> <span>Projects & Publications</span></p>
	            <h1 class="bread">Projects & Publications</h1>
	          	</div>
	        	</div>
				</div>
			</section>


			<section class="ftco-section">
	    		<div class="container">
	    		<div class="row justify-content-center align-items-center">
	          	

	          	<!-- Project 1 -->
				<div class="blog-entry ftco-animate d-md-flex">
				<a href="https://github.com/tensorflow/swift-models" class="img" style="background-image: url(images/sw4tf.png);"></a>

				<div class="text p-4">
				<h3 class=""><a href="https://github.com/tensorflow/swift-models">DeepLabV3+ Implementation using TF2.x and Swift for TensorFlow</a></h3>
				<p class="">A joint effort with <a href="https://research.google/teams/brain/">Google Brain</a> to show the potential of SwiftFusion in which factor graphs and deep learning come together. Details to be <a href="">updated soon</a>.
				</p>
				</div>
				</div>


	    		<!-- Project 1 -->
				<div class="blog-entry ftco-animate d-md-flex">
				<a href="https://bethanystate.github.io/CS7641_project/" class="img" style="background-image: url(https://github.com/diwakar-vsingh/Neural-Style-Transfer-using-CycleGAN/blob/master/Results/Neural%20Style%20Transfer.gif?raw=true);"></a>

				<div class="text p-4">
				<h3 class=""><a href="https://bethanystate.github.io/CS7641_project/">Neural Style Transfer using CycleGAN</a></h3>
				<p class="">Unpaired image-to-image translation is a class of vision and graphics problems where the goal is to learn the mapping between two image domains. <a href="https://arxiv.org/abs/1508.06576">Neural Style Transfer </a> is one way to perform image-to-image translation, which synthesizes a novel image by combining the content of one image with the style of another image. Unlike recent work on “neural style transfer”, we used <a href="https://arxiv.org/abs/1703.10593"> CycleGAN </a> method which learns to mimic the style of an entire collection of artworks, rather than transferring the style of a single selecterd piece of art. 
				</p>
				</div>
				</div>


				<!-- Project 2 -->
				<div class="blog-entry ftco-animate d-md-flex">
				<a href="https://github.com/diwakar-vsingh/Integrated-Gradients" class="img" style="background-image: url(https://github.com/diwakar-vsingh/Integrated-Gradients/blob/master/Results/baseline.gif?raw=true);"></a>

				<div class="text p-4">
				<h3 class=""><a href="https://github.com/diwakar-vsingh/Integrated-Gradients/blob/master/Integrated%20Gradients.ipynb">Visualization of the Impact of Integrated Gradient Method</a></h3>
				<p class="">This project studied the Integrated Gradients (IG) attribution method, an <a href="https://en.wikipedia.org/wiki/Explainable_artificial_intelligence"> Explainable AI </a> technique introduced in the paper <a href="https://arxiv.org/abs/1703.01365">Axiomatic Attribution for Deep Networks</a>. The IG method is successfully implemented on an image classification task using the <a href="https://tfhub.dev/google/imagenet/inception_v1/classification/4"> Inception V1 </a> network trained on ImageNet dataset. The project also investigated the effect of using different baselines to determine the sensitivity of this method to the input baseline hyperparameter.
				</p>
				</div>
				</div>


	         	<!-- Project 3 -->
	          	<div class="blog-entry ftco-animate d-md-flex">
				<a href="https://github.com/diwakar-vsingh/Debiased-VAE" class="img" style="background-image: url(https://media1.tenor.com/images/44e1f590924eca94fe86067a4cf44c72/tenor.gif?itemid=3394328);"></a>

				<div class="text p-4">
				<h3 class=""><a href="https://github.com/diwakar-vsingh/Debiased-VAE">Debiasing Facial Detection Systems</a></h3>
				<p class=""> In this project, two prominent aspects of applied deep learning are explored, i.e. facial detection and algorithmic bias. Deploying fair, unbiased AI systems is critical to their long-term acceptance. Consider the task of facial detection: given an image, is it an image of a face? This seemingly simple, but extremely important, task is subject to significant amounts of algorithmic bias among select demographics. Here, we investigated <a href="http://introtodeeplearning.com/AAAI_MitigatingAlgorithmicBias.pdf"> one recently published approach </a> to addressing algorithmic bias. 
				</p>
				</div>
				</div>


				<!-- Project 4 -->
				<div class="blog-entry ftco-animate d-md-flex">
				<a href="" class="img" style="background-image: url(https://github.com/diwakar-vsingh/EKF-SLAM/blob/master/results.gif?raw=true);"></a>

				<div class="text p-4">
				<h3 class=""><a href="">MonoSLAM using EKF Filtering for Wheeled Mobile Robot</a></h3>
				<p class="">This project implements MonoSLAM on the wheeled robot using the <a href="https://www.doc.ic.ac.uk/~ajd/Publications/civera_etal_jfr2010.pdf">1-Point RANSAC for EKF filtering</a>. To make the implementation quite, the is search space is narrowed down for each feature from the whole image to a small ellipse where the feature is predicted to lie. For the closed-loop SLAM operation, a custom deep CNN is built which combines semantic segmentation, VAE, and triplet embedding network. The trained network is used to construct a global feature space to describe both the visual appearance and semantic layout of an image.
				</p>
				</div>
				</div>


				<!-- Project 5 -->
				<div class="blog-entry ftco-animate d-md-flex">
				<div class="img-2">
				<audio controls>
  					<source src="https://github.com/diwakar-vsingh/Music-Gneration-with-RNNs/blob/master/DL%20Music.mp3?raw=true" type="audio/mpeg">
					Your browser does not support the audio element.
				</audio>
				</div>
				<div class="text p-4">
				<h3 class=""><a href="https://github.com/diwakar-vsingh/Music-Gneration-with-RNNs">Music Generation with RNNs</a></h3>
				<p class="">This project explores building a Recurrent Neural Network (RNN) for music generation using <a href="https://www.tensorflow.org/"> TensorFlow APIs </a>. A model is trained to learn the patterns in a dataset of thousands of Irish folk songs, represented in the <a href="https://en.wikipedia.org/wiki/ABC_notation">ABC notation</a>. The RNN model is based off the LSTM architecture, where a state vector is used to maintain information about the temporal relationships between consecutive characters. For inference, output distributions are iteratively sampled and are encoded to generate song in the ABC format.
				</p>
				</div>
				</div>


				<!-- Project 6 -->
				<div class="blog-entry ftco-animate d-md-flex">
				<a href="single.html" class="img" style="background-image: url(https://github.com/diwakar-vsingh/Convolutional-Variational-Autoencoder/blob/master/CVAE.gif?raw=true);"></a>

				<div class="text p-4">
				<h3 class=""><a href="single.html">Convolutional Variational Autoencoder</a></h3>
				<p class="">This project demonstrates how to train a <a href="https://arxiv.org/abs/1312.6114"> Variational Autoencoder (VAE) </a> on the <a href="http://yann.lecun.com/exdb/mnist/"> MNIST dataset </a> using <a href="https://www.tensorflow.org/"> TensorFlow APIs </a>. A VAE is a probabilistic take on the autoencoder, a model which takes high dimensional input data compress it into a smaller representation. Unlike a traditional autoencoder, which maps the input onto a latent vector, a VAE maps the input data into the parameters of a probability distribution, such as the mean and variance of a Gaussian. This approach produces a continuous, structured latent space, which is useful for image generation.
				</p>
				</div>
				</div>
	

			   	<!-- Project 7 -->
				<div class="blog-entry ftco-animate d-md-flex">
				<a href="" class="img" style="background-image: url(https://www.tensorflow.org/tutorials/reinforcement_learning/actor_critic_files/output_TLd720SejKmf_0.gif);"></a>

				<div class="text p-4">
				<h3 class=""><a href="">Control of Cart Pole using Reinforcement Learning</a></h3>
				<p class="">In this project, the <a href="https://papers.nips.cc/paper/1786-actor-critic-algorithms.pdf">Actor-Critic</a> method is implemented to train an agent on the <a href="https://gym.openai.com/">Open AI Gym</a> <a href="https://gym.openai.com/envs/CartPole-v0">CartPole-V0 environment</a> to control cartpole. In Cartpole, a pole is attached by an un-actuated joint to a cart, which moves along a frictionless track. The pole starts upright, and the goal is to prevent it from falling over by applying a force of -1 or +1 to the cart. A reward of +1 is given for every time step the pole remains upright. An episode ends when (1) the pole is more than 15 degrees from vertical or (2) the cart moves more than 2.4 units from the center.
				</p>
				</div>
				</div>


				<!-- Project 8 -->
				<div class="blog-entry ftco-animate d-md-flex">
				<a href="https://github.com/diwakar-vsingh/Adaptive-Structures/raw/master/EMI.pptx" class="img" style="background-image: url(https://github.com/diwakar-vsingh/Adaptive-Structures/blob/master/testAnimated.gif?raw=true);"></a>

				<div class="text p-4">
				<h3 class=""><a href="https://github.com/diwakar-vsingh/Adaptive-Structures/raw/master/EMI.pptx">Potential for Bio-inspired Adaptable Design in Structural Engineering</a></h3>
				<p class="">Over years the design of structures advanced with the availability of historical data and improvement of probabilistic methods. In these structural engineering design approaches, the
				initial problem constraints are governed by past influences. As climate change and other man-made events rapidly alter our environment, this work seeks to explore a new paradigm in which past influences are removed in order to drive innovation. The removal of the predetermined loading conditions will yield a structure that is not specifically designed for given hazards, but adaptable for any environment.
				</p>
				</div>
				</div>


				<!-- Project 9 -->
				<div class="blog-entry ftco-animate d-md-flex">
				<a href="https://doi.org/10.1016/j.proeng.2016.12.253" class="img" style="background-image: url(images/plaxis.jpg);"></a>

				<div class="text p-4">
				<h3 class=""><a href="https://doi.org/10.1016/j.proeng.2016.12.253">3D Modelling of Ground Surface Vibration Induced by Underground Train Movement</a></h3>
				<p class="">The force distribution due to axle loads, with respect to the moving referential is modelled using the Finite Element Analysis software called <a href="https://www.plaxis.com/">PLAXIS 3D</a>. The matrix of dynamic multipliers for each static point load is genertaed and applied along the railway track with each time step. The results can be used for gauging the effect of changing various geological and physical parameters on the distribution of force due to axle load. Once calibrated to geotechnical and physical data corresponding to sites above actual underground train tracks, the model can be used to predict the effect of vibrations on existing infrastructure. 
				</p>
				</div>
				</div>


				<!-- Project 10 -->
				<div class="blog-entry ftco-animate d-md-flex">
				<a href="https://www.researchgate.net/publication/338396298_FAILURE_PROBABILITY_OF_INDUSTRIAL_STEEL_STRUCTURES_SUBJECTED_TO_NON-_STATIONARY_EARTHQUAKE_AND_WIND_HAZARD" class="img" style="background-image: url(images/Failure.jpg);"></a>

				<div class="text p-4">
				<h3 class=""><a href="https://www.researchgate.net/publication/338396298_FAILURE_PROBABILITY_OF_INDUSTRIAL_STEEL_STRUCTURES_SUBJECTED_TO_NON-_STATIONARY_EARTHQUAKE_AND_WIND_HAZARD">Failure Probability of Industrial Structures subjected to Non-stationary Earthquake and Wind Hazards</a></h3>
				<p class="">The multi-hazard effects on moment resisting (MR) industrial unbraced and braced steel frame buildings are assessed independently under non-stationary earthquake and wind induced forces. Joint probabilities of failure are determined in terms of probability density functions (PDFs) and cumulative distribution functions (CDFs) by conducting fragility analysis against each natural hazard independently.
				</p>
				</div>
				</div>

				</div> 
			   	</div>
	    	</section>
	   
		</div><!-- END COLORLIB-MAIN -->
	</div><!-- END COLORLIB-PAGE -->

  <!-- loader -->
  <div id="ftco-loader" class="show fullscreen"><svg class="circular" width="48px" height="48px"><circle class="path-bg" cx="24" cy="24" r="22" fill="none" stroke-width="4" stroke="#eeeeee"/><circle class="path" cx="24" cy="24" r="22" fill="none" stroke-width="4" stroke-miterlimit="10" stroke="#F96D00"/></svg></div>


  <script src="js/jquery.min.js"></script>
  <script src="js/jquery-migrate-3.0.1.min.js"></script>
  <script src="js/popper.min.js"></script>
  <script src="js/bootstrap.min.js"></script>
  <script src="js/jquery.easing.1.3.js"></script>
  <script src="js/jquery.waypoints.min.js"></script>
  <script src="js/jquery.stellar.min.js"></script>
  <script src="js/owl.carousel.min.js"></script>
  <script src="js/jquery.magnific-popup.min.js"></script>
  <script src="js/aos.js"></script>
  <script src="js/jquery.animateNumber.min.js"></script>
  <script src="js/bootstrap-datepicker.js"></script>
  <script src="js/jquery.timepicker.min.js"></script>
  <script src="js/scrollax.min.js"></script>
  <script src="https://maps.googleapis.com/maps/api/js?key=AIzaSyBVWaKrjvy3MaE7SQ74_uJiULgl1JY0H2s&sensor=false"></script>
  <script src="js/google-map.js"></script>
  <script src="js/main.js"></script>
    
  </body>
</html>